{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9facc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f5ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load \n",
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130cce4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Publication_Day</th>\n",
       "      <th>Publication_Time</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Episode_Sentiment</th>\n",
       "      <th>Listening_Time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mystery Matters</td>\n",
       "      <td>Episode 98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True Crime</td>\n",
       "      <td>74.81</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>31.41998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Joke Junction</td>\n",
       "      <td>Episode 26</td>\n",
       "      <td>119.80</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>66.95</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>75.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>88.01241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Study Sessions</td>\n",
       "      <td>Episode 16</td>\n",
       "      <td>73.90</td>\n",
       "      <td>Education</td>\n",
       "      <td>69.97</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>44.92531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Digital Digest</td>\n",
       "      <td>Episode 45</td>\n",
       "      <td>67.17</td>\n",
       "      <td>Technology</td>\n",
       "      <td>57.22</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Morning</td>\n",
       "      <td>78.70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>46.27824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mind &amp; Body</td>\n",
       "      <td>Episode 86</td>\n",
       "      <td>110.51</td>\n",
       "      <td>Health</td>\n",
       "      <td>80.07</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>58.68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>75.61031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
       "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
       "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
       "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
       "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
       "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
       "\n",
       "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
       "0                       74.81        Thursday            Night   \n",
       "1                       66.95        Saturday        Afternoon   \n",
       "2                       69.97         Tuesday          Evening   \n",
       "3                       57.22          Monday          Morning   \n",
       "4                       80.07          Monday        Afternoon   \n",
       "\n",
       "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
       "0                          NaN            0.0          Positive   \n",
       "1                        75.95            2.0          Negative   \n",
       "2                         8.97            0.0          Negative   \n",
       "3                        78.70            2.0          Positive   \n",
       "4                        58.68            3.0           Neutral   \n",
       "\n",
       "   Listening_Time_minutes  \n",
       "0                31.41998  \n",
       "1                88.01241  \n",
       "2                44.92531  \n",
       "3                46.27824  \n",
       "4                75.61031  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010a947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing Value\n",
    "def missing_vaule(df):\n",
    "    df['Episode_Length_minutes']=df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].mean())\n",
    "    df['Guest_Popularity_percentage']=df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].mean())\n",
    "    df['Number_of_Ads']=df['Number_of_Ads'].fillna(df_train['Number_of_Ads'].mean())\n",
    "   \n",
    "        \n",
    "missing_vaule(df_train)\n",
    "missing_vaule(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c71c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnecessary colmun delete\n",
    "\n",
    "drop_col=['Podcast_Name','Episode_Title']\n",
    "df_train.drop(drop_col,inplace=True,axis=1)\n",
    "df_test.drop(drop_col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1747c",
   "metadata": {},
   "source": [
    "# Encodeing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce89ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodeing Day Colmuns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize encoder to handle unknown categories and drop first category\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit on training data and transform both train and test\n",
    "encode_day = encoder.fit_transform(df_train[['Publication_Day']])\n",
    "encode_day_t = encoder.transform(df_test[['Publication_Day']])  # Note: Make sure column name matches\n",
    "\n",
    "# Create DataFrames with feature names\n",
    "encoded_df = pd.DataFrame(encode_day, \n",
    "                         columns=encoder.get_feature_names_out([\"Publication_Day\"]))\n",
    "encoded_df_t = pd.DataFrame(encode_day_t,\n",
    "                           columns=encoder.get_feature_names_out([\"Publication_Day\"]))\n",
    "\n",
    "# Concatenate with original data\n",
    "df_train = pd.concat([df_train.drop(\"Publication_Day\", axis=1), encoded_df], axis=1)\n",
    "df_test = pd.concat([df_test.drop(\"Publication_Day\", axis=1), encoded_df_t], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff1e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pervezhasan/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pervezhasan/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Label Encodeinng Episode_Sentiment\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "la=LabelEncoder()\n",
    "\n",
    "df_train['Episode_Sentiment']=la.fit_transform(df_train[['Episode_Sentiment']])\n",
    "df_test['Episode_Sentiment']=la.transform(df_test[['Episode_Sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e5b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encodeing Publication_Time\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ode=OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# ট্রেন ডেটায় ফিট করুন\n",
    "ode.fit(df_train[['Publication_Time']])\n",
    "\n",
    "# উভয় ডেটাসেট ট্রান্সফর্ম করুন\n",
    "df_train['Publication_Time'] = ode.transform(df_train[['Publication_Time']])\n",
    "df_test['Publication_Time'] = ode.transform(df_test[['Publication_Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2520f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize encoder to handle unknown categories\n",
    "ohe = OneHotEncoder(drop='first',handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit on training data\n",
    "train_encoded = ohe.fit_transform(df_train[['Genre']])\n",
    "\n",
    "# Transform both datasets\n",
    "test_encoded = ohe.transform(df_test[['Genre']])\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_encoded_df = pd.DataFrame(train_encoded, \n",
    "                               columns=ohe.get_feature_names_out(['Genre']))\n",
    "test_encoded_df = pd.DataFrame(test_encoded,\n",
    "                              columns=ohe.get_feature_names_out(['Genre']))\n",
    "\n",
    "# Concatenate with original data\n",
    "df_train = pd.concat([df_train.drop('Genre', axis=1), train_encoded_df], axis=1)\n",
    "df_test = pd.concat([df_test.drop('Genre', axis=1), test_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c29b9",
   "metadata": {},
   "source": [
    "# Scaleling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ec0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8410aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# List of columns to scale\n",
    "columns_to_scale = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage']\n",
    "\n",
    "# 1. Create StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit the scaler on the selected columns of the training data\n",
    "scaler.fit(df_train[columns_to_scale])\n",
    "\n",
    "# 3. Transform the selected columns in both train and test data, replacing original columns\n",
    "df_train[columns_to_scale] = scaler.transform(df_train[columns_to_scale])\n",
    "df_test[columns_to_scale] = scaler.transform(df_test[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f228e59a",
   "metadata": {},
   "source": [
    "# Model Bulideing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c38d65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df_train.drop(columns=['Listening_Time_minutes'])\n",
    "y=df_train['Listening_Time_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3c142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d43f507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a29f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/pervezhasan/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2.post1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in /home/pervezhasan/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n",
      "\u001b[2K   \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/253.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:01:23\u001b[0m:23\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1746fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Predict=model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eed706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# সাবমিশন ফাইল তৈরি করুন\n",
    "submission = pd.DataFrame({\n",
    "    'id':df_test['id'],\n",
    "    'Listening_Time_minutes': final_Predict\n",
    "})\n",
    "submission.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16722032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [179.91378676 179.06898624 178.86585703 179.74645023 178.69909441]\n",
      "Mean CV MSE: 179.2588349322071\n",
      "STD CV MSE: 0.4838417480363118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# 5-fold CV এর জন্য\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=model,\n",
    "    X=X_train,  # ফিচার ম্যাট্রিক্স\n",
    "    y=y_train,  # টার্গেট ভেরিয়েবল\n",
    "    cv=5,       # 5 ফোল্ড\n",
    "    scoring='neg_mean_squared_error'  # স্কোরিং মেট্রিক\n",
    ")\n",
    "\n",
    "# রেজাল্ট প্রিন্ট\n",
    "print(\"CV Scores:\", -cv_scores)  # নেগেটিভ MSE কে পজিটিভ করুন\n",
    "print(\"Mean CV MSE:\", -cv_scores.mean())\n",
    "print(\"STD CV MSE:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba189f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa331d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
