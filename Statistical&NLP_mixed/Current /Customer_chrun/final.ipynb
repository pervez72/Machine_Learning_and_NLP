{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4221ff",
   "metadata": {},
   "source": [
    "# Industry-Level Logistic Regression Implementation\n",
    "\n",
    "Here's a production-ready logistic regression implementation following industry best practices:\n",
    "\n",
    "## Complete Implementation\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, confusion_matrix, \n",
    "                            classification_report)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import logging\n",
    "from typing import Tuple, Union\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LogisticRegressionModel:\n",
    "    \"\"\"\n",
    "    Industry-grade logistic regression classifier with full ML pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params: dict = None):\n",
    "        \"\"\"Initialize with default or custom parameters\"\"\"\n",
    "        self.default_params = {\n",
    "            'penalty': 'l2',\n",
    "            'C': 1.0,\n",
    "            'solver': 'lbfgs',\n",
    "            'max_iter': 1000,\n",
    "            'random_state': 42,\n",
    "            'class_weight': 'balanced'\n",
    "        }\n",
    "        self.params = params or self.default_params\n",
    "        self.model = None\n",
    "        self.preprocessor = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def build_preprocessor(self, numeric_features: list, categorical_features: list) -> ColumnTransformer:\n",
    "        \"\"\"Create preprocessing pipeline for different feature types\"\"\"\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ])\n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: Union[pd.Series, np.ndarray], \n",
    "              numeric_features: list, categorical_features: list) -> None:\n",
    "        \"\"\"\n",
    "        Train logistic regression model with full pipeline\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if not isinstance(X, pd.DataFrame):\n",
    "                raise ValueError(\"X must be a pandas DataFrame\")\n",
    "                \n",
    "            if len(X) != len(y):\n",
    "                raise ValueError(\"X and y must have same length\")\n",
    "            \n",
    "            logger.info(\"Building preprocessing pipeline...\")\n",
    "            self.preprocessor = self.build_preprocessor(numeric_features, categorical_features)\n",
    "            \n",
    "            # Create full pipeline\n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', self.preprocessor),\n",
    "                ('classifier', LogisticRegression(**self.params))\n",
    "            ])\n",
    "            \n",
    "            logger.info(\"Training model...\")\n",
    "            pipeline.fit(X, y)\n",
    "            self.model = pipeline\n",
    "            self.feature_names = numeric_features + categorical_features\n",
    "            \n",
    "            logger.info(\"Model training completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during model training: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Make class predictions\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"Model not trained yet. Call train() first.\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"Get prediction probabilities\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"Model not trained yet. Call train() first.\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X_test: pd.DataFrame, y_test: Union[pd.Series, np.ndarray]) -> dict:\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        y_pred = self.predict(X_test)\n",
    "        y_proba = self.predict_proba(X_test)[:, 1] if hasattr(self.model, \"predict_proba\") else None\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        metrics['precision'] = precision_score(y_test, y_pred)\n",
    "        metrics['recall'] = recall_score(y_test, y_pred)\n",
    "        metrics['f1'] = f1_score(y_test, y_pred)\n",
    "        \n",
    "        if y_proba is not None:\n",
    "            metrics['roc_auc'] = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "        metrics['classification_report'] = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def hyperparameter_tuning(self, X: pd.DataFrame, y: Union[pd.Series, np.ndarray], \n",
    "                            param_grid: dict, cv: int = 5) -> None:\n",
    "        \"\"\"Perform grid search for hyperparameter tuning\"\"\"\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=self.model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        self.model = grid_search.best_estimator_\n",
    "        logger.info(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "        \n",
    "    def save_model(self, filepath: str) -> None:\n",
    "        \"\"\"Save trained model to disk\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"Model not trained yet. Call train() first.\")\n",
    "        joblib.dump(self.model, filepath)\n",
    "        logger.info(f\"Model saved to {filepath}\")\n",
    "        \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str) -> 'LogisticRegressionModel':\n",
    "        \"\"\"Load trained model from disk\"\"\"\n",
    "        model = joblib.load(filepath)\n",
    "        new_instance = cls()\n",
    "        new_instance.model = model\n",
    "        return new_instance\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data - replace with your actual data\n",
    "    data = pd.DataFrame({\n",
    "        'age': [25, 30, 35, 40, 45],\n",
    "        'income': [40000, 50000, 60000, 70000, 80000],\n",
    "        'gender': ['M', 'F', 'M', 'F', 'M'],\n",
    "        'purchased': [0, 1, 0, 1, 1]\n",
    "    })\n",
    "    \n",
    "    # Prepare data\n",
    "    X = data.drop('purchased', axis=1)\n",
    "    y = data['purchased']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define feature types\n",
    "    numeric_features = ['age', 'income']\n",
    "    categorical_features = ['gender']\n",
    "    \n",
    "    # Initialize and train model\n",
    "    lr_model = LogisticRegressionModel()\n",
    "    lr_model.train(X_train, y_train, numeric_features, categorical_features)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics = lr_model.evaluate(X_test, y_test)\n",
    "    print(\"Model Metrics:\", metrics)\n",
    "    \n",
    "    # Save model\n",
    "    lr_model.save_model('logistic_regression_model.joblib')\n",
    "    \n",
    "    # Load model\n",
    "    loaded_model = LogisticRegressionModel.load_model('logistic_regression_model.joblib')\n",
    "    print(\"Model loaded successfully\")\n",
    "```\n",
    "\n",
    "## Key Industry-Standard Features\n",
    "\n",
    "1. **Modular Design**: \n",
    "   - Separate preprocessing, training, and evaluation\n",
    "   - Clean class-based implementation\n",
    "\n",
    "2. **Robust Data Handling**:\n",
    "   - Automatic handling of numeric and categorical features\n",
    "   - Proper type checking and error handling\n",
    "\n",
    "3. **Comprehensive Evaluation**:\n",
    "   - Multiple metrics (accuracy, precision, recall, F1, ROC AUC)\n",
    "   - Confusion matrix and classification report\n",
    "\n",
    "4. **Production-Ready Features**:\n",
    "   - Hyperparameter tuning with GridSearchCV\n",
    "   - Model serialization with joblib\n",
    "   - Logging for monitoring\n",
    "\n",
    "5. **Type Hints**:\n",
    "   - Clear function signatures with type annotations\n",
    "   - Better IDE support and code maintainability\n",
    "\n",
    "6. **Documentation**:\n",
    "   - Detailed docstrings for all methods\n",
    "   - Example usage included\n",
    "\n",
    "## Best Practices Followed\n",
    "\n",
    "- Proper separation of concerns\n",
    "- Exception handling and logging\n",
    "- Configurable through parameters\n",
    "- Support for both training and inference\n",
    "- Model persistence capabilities\n",
    "- Comprehensive evaluation metrics\n",
    "- Feature preprocessing pipeline\n",
    "- Hyperparameter optimization\n",
    "\n",
    "This implementation is ready for deployment in production environments and follows all modern ML engineering best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f17056",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'ğŸ“' (U+1F4C1) (672289613.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    ğŸ“ telco_churn_project/\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'ğŸ“' (U+1F4C1)\n"
     ]
    }
   ],
   "source": [
    "ğŸ“ telco_churn_project/\n",
    "â”œâ”€â”€ main.py                        # à¦ªà§à¦°à¦§à¦¾à¦¨ à¦°à¦¾à¦¨ à¦•à¦°à¦¾à¦° à¦«à¦¾à¦‡à¦²\n",
    "â”œâ”€â”€ config.yaml                   # à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨\n",
    "â”œâ”€â”€ requirements.txt             # à¦ªà§à¦°à§Ÿà§‹à¦œà¦¨à§€à§Ÿ à¦²à¦¾à¦‡à¦¬à§à¦°à§‡à¦°à¦¿\n",
    "â”œâ”€â”€ ğŸ“ src/\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ data_loader.py           # CSV à¦²à§‹à¦¡ à¦•à¦°à¦¾\n",
    "â”‚   â”œâ”€â”€ preprocessing.py         # à¦ªà§à¦°à¦¿à¦ªà§à¦°à¦¸à§‡à¦¸à¦¿à¦‚ à¦“ à¦«à¦¿à¦šà¦¾à¦° à¦‡à¦à§à¦œà¦¿à¦¨à¦¿à§Ÿà¦¾à¦°à¦¿à¦‚\n",
    "â”‚   â”œâ”€â”€ model_train.py           # à¦®à¦¡à§‡à¦² à¦Ÿà§à¦°à§‡à¦¨à¦¿à¦‚ à¦“ à¦‡à¦­à¦¾à¦²à§à§Ÿà§‡à¦¶à¦¨\n",
    "â”‚   â”œâ”€â”€ utils.py                 # Utility functions\n",
    "â”œâ”€â”€ ğŸ“ models/                    # Trained à¦®à¦¡à§‡à¦² à¦¸à§‡à¦­ à¦¹à¦¬à§‡ à¦à¦–à¦¾à¦¨à§‡\n",
    "â”œâ”€â”€ ğŸ“ logs/                      # à¦²à¦— à¦«à¦¾à¦‡à¦²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98861013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
